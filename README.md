# Chat with Docs

## Overview
This project is a Streamlit-based application designed for managing and querying PDF documents using natural language processing (NLP) and vector-based search techniques. It allows users to:
- Upload PDF documents to a "brain" (a collection of documents).
- Query the documents using natural language questions.
- View a list of uploaded documents in a scrollable interface.

The application leverages:
- **LangChain** for document processing and question-answering.
- **Chroma** for vector-based document storage and retrieval.
- **Ollama** for embeddings and language models.

---

## Project Structure
brain-based-document-management/
- **app.py**: The main application file that handles the user interface and interactions.
- **config.py**: Contains configuration settings for the application.
- **requirements.txt**: Lists the Python dependencies required for the project.
- **README.md**: Provides documentation and information about the project.
- **utils/**: Directory containing utility modules for various functionalities.
  - **file_utils.py**: Utilities for handling file uploads and processing.
  - **vector_store_utils.py**: Utilities for managing the vector store.
  - **llm_utils.py**: Utilities for interacting with the language model.
- **data/**: Directory for storing uploaded documents, organized by brain names.



---

## Features
1. **Brain Management**:
   - Create or select a "brain" (a collection of documents).
   - Upload PDF documents to a brain.
2. **Document Indexing**:
   - Automatically split PDFs into chunks for processing.
   - Index documents into a Chroma vector store for efficient retrieval.
3. **Question Answering**:
   - Ask natural language questions about the documents in a brain.
   - Get concise answers generated by a language model.
4. **Document List**:
   - View a scrollable list of all uploaded documents in a brain.

---

## Setup Instructions

### Prerequisites
- Python 3.8 or higher.
- [Streamlit](https://streamlit.io/) installed.
- [Ollama](https://ollama.ai/) running locally for embeddings and language models.

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/brain-based-document-management.git
   cd brain-based-document-management

2. Clone the repository:
pip install -r requirements.txt

3. Ensure Ollama is running locally with the required model (deepseek-r1:1.5b).
4. Ensure ChromaDB is running locally


### Usage
Run the Streamlit app:

bash
Copy
streamlit run app.py
Open your browser and navigate to the provided URL (usually http://localhost:8501).

Create or Select a Brain:

Enter a name for a new brain or select an existing one from the dropdown.

Upload PDFs:

Use the file uploader to upload a PDF document.

The document will be processed and indexed automatically.

### Ask Questions:

Enter a question in the chat input box.

The app will retrieve relevant documents and generate an answer.

View Uploaded Documents:

A scrollable list of uploaded documents is displayed under the "Uploaded Documents" section.

### Configuration
The following configuration options are available in config.py:

OLLAMA_MODEL: The Ollama model to use for embeddings and language models.

PDFS_BASE_DIR: The base directory for storing uploaded PDFs.

CHROMA_PERSIST_DIR: The directory for persisting the Chroma vector store.

HASH_FILE: The file for storing document hashes to track duplicates.

### Dependencies
Streamlit: For the web interface.

LangChain: For document processing and question-answering.

Chroma: For vector-based document storage and retrieval.

Ollama: For embeddings and language models.

PDFPlumber: For loading and processing PDF documents.

See requirements.txt for the full list of dependencies.

## Contributing
Contributions are welcome! If you'd like to contribute, please follow these steps:

Fork the repository.

Create a new branch for your feature or bugfix.

Commit your changes and push to your branch.

Submit a pull request with a detailed description of your changes.

## License
This project is licensed under the MIT License. See the LICENSE file for details.

## Acknowledgments
Streamlit for the web framework.

LangChain for NLP and document processing.

Ollama for embeddings and language models.

Chroma for vector-based document storage.

## Contact
For questions or feedback, please open an issue on GitHub or contact the maintainer:

Reda KAMRAOUI: redakamraoui@gmail.com
GitHub: Reda-Abdellah

Jan MARGETA




